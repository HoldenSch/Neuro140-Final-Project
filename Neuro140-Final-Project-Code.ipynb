{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2d0e741-f2eb-4c29-bb03-6e16fa845f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tile set: #%-12@BCEFGKLMQSTUXbot|\n"
     ]
    }
   ],
   "source": [
    "import os, math, random, numpy as np, torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "TRAIN_LEVEL_DIR = \"./levels\"\n",
    "OUTPUT_DIR      = \"./generated_levels\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# auto‑extract symbols\n",
    "symbols = {\"-\"}\n",
    "for fn in os.listdir(TRAIN_LEVEL_DIR):\n",
    "    if fn.endswith(\".txt\"):\n",
    "        with open(os.path.join(TRAIN_LEVEL_DIR, fn)) as f:\n",
    "            for line in f:\n",
    "                symbols.update(line.rstrip())\n",
    "symbols = sorted(symbols)\n",
    "int_to_char = {i: ch for i, ch in enumerate(symbols)}\n",
    "char_to_int = {ch: i for i, ch in int_to_char.items()}\n",
    "\n",
    "LEVEL_HEIGHT  = 16              \n",
    "LEVEL_WIDTH   = 200\n",
    "PATCH         = 16             \n",
    "LATENT_DIM    = 128\n",
    "BATCH_SIZE    = 64\n",
    "EPOCHS        = 30\n",
    "MAX_TILE      = len(int_to_char) - 1\n",
    "\n",
    "GROUND = {char_to_int.get(c) for c in (\"X\",\"S\")} - {None}\n",
    "ENEMIES= {char_to_int.get(c) for c in (\"G\",\"k\",\"g\",\"Y\",\"y\")} - {None}\n",
    "START  = char_to_int.get(\"M\", 1)\n",
    "GOAL   = char_to_int.get(\"F\", 2)\n",
    "\n",
    "print(\"Tile set:\", \"\".join(symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9870c16a-71a0-4ac4-a79e-21717e448251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16×16 patches: 12012\n"
     ]
    }
   ],
   "source": [
    "def ascii_to_grid(lines):\n",
    "    # Convert a list of ASCII strings to a numeric grid using tile mappings\n",
    "    g = np.zeros((LEVEL_HEIGHT, LEVEL_WIDTH), np.uint8)\n",
    "    for r, l in enumerate(lines[:LEVEL_HEIGHT]):\n",
    "        for c, ch in enumerate(l.rstrip()[:LEVEL_WIDTH]):\n",
    "            g[r, c] = char_to_int.get(ch, 0)  # Default to 0 (usually sky) if unknown\n",
    "    return g\n",
    "\n",
    "def iter_patches(grid):\n",
    "    # Yield non-overlapping 16-tile-wide patches from the full grid\n",
    "    for x in range(0, LEVEL_WIDTH - PATCH + 1, PATCH):\n",
    "        yield grid[:, x:x+PATCH]\n",
    "\n",
    "class Mario16(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        buf = []\n",
    "        # Read and process all .txt level files in the folder\n",
    "        for fn in os.listdir(folder):\n",
    "            if fn.endswith(\".txt\"):\n",
    "                with open(os.path.join(folder, fn)) as f:\n",
    "                    buf.extend(iter_patches(ascii_to_grid(f.readlines())))\n",
    "        self.data = np.stack(buf)  # Stack patches into a numpy array\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Normalize tile IDs and convert to PyTorch tensor with channel dimension\n",
    "        x = self.data[i] / MAX_TILE\n",
    "        return torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "# Create DataLoader for training batches of 16×16 level segments\n",
    "loader = DataLoader(Mario16(TRAIN_LEVEL_DIR),\n",
    "                    batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "print(\"16×16 patches:\", len(loader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "361aa732-58b1-4f4e-8f8e-db558c1a2bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (body): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (avg): AdaptiveAvgPool2d(output_size=(4, 4))\n",
       "  (head): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (2): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def w_init(m):\n",
    "    # Initialize weights for Conv and Linear layers using a normal distribution\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
    "        nn.init.normal_(m.weight, 0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(LATENT_DIM, 1024 * 4 * 4), nn.ReLU(True)  # Map latent vector to 4x4 feature map\n",
    "        )\n",
    "        self.up1 = nn.Sequential(  # Upsample: 4×4 → 8×8\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1),\n",
    "            nn.BatchNorm2d(512), nn.ReLU(True)\n",
    "        )\n",
    "        self.up2 = nn.Sequential(  # Upsample: 8×8 → 16×16 + refinement\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256), nn.ReLU(True),\n",
    "            nn.Conv2d(256, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128), nn.ReLU(True)\n",
    "        )\n",
    "        self.out = nn.Sequential(  # Final output layer with Sigmoid to normalize to [0, 1]\n",
    "            nn.Conv2d(128, 1, 3, 1, 1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z).view(-1, 1024, 4, 4)         # Reshape to 4×4 feature map\n",
    "        x = self.up1(x)                             # Upsample to 8×8\n",
    "        x = x + torch.randn_like(x) * 0.05          # Add noise for diversity\n",
    "        x = self.up2(x)                             # Upsample to 16×16\n",
    "        return self.out(x)                          # Output shape: (B,1,16,16)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 4, 2, 1), nn.LeakyReLU(0.2, True),     # Downsample: 16×16 → 8×8\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, True)                                 # Downsample: 8×8 → 4×4\n",
    "        )\n",
    "        self.avg = nn.AdaptiveAvgPool2d((4, 4))                     # Ensure consistent 4×4 output\n",
    "        self.head = nn.Sequential(                                  # Final binary classification head\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(self.avg(self.body(x)))  # Output: probability of being real\n",
    "\n",
    "# Instantiate generator and discriminator and apply weight initialization\n",
    "Gnet, Dnet = Generator().to(device), Discriminator().to(device)\n",
    "Gnet.apply(w_init)\n",
    "Dnet.apply(w_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0431353-da76-4a7b-a0e4-bcffcf3343de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DifficultyConfig:\n",
    "    # Stores parameters that control level difficulty\n",
    "    pit_freq: float         # Expected number of pits per 100 tiles\n",
    "    pit_width_mean: float   # Average pit width in tiles\n",
    "    sky_max_clear: float    # Probability of removing bad sky tiles in top row\n",
    "    sky_min_clear: float    # Probability of removing bad sky tiles near ground\n",
    "    sky_curve: str = \"linear\"  # Tapering curve for sky clearing: 'exp', 'linear', or 'quad'\n",
    "    seed: int = 0              # Random seed for reproducible decorations (0 = random)\n",
    "\n",
    "# Predefined difficulty settings (can be modified as needed)\n",
    "PRESETS = {\n",
    "    \"easy\":   DifficultyConfig(0.05, 1.0, 0.98, 0.75),\n",
    "    \"medium\":   DifficultyConfig(0.10, 1.5, 0.95, 0.65),\n",
    "    \"hard\": DifficultyConfig(0.30, 2.0, 0.90, 0.50),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68012b35-7f72-47f0-a701-233ba2039d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with:\n",
      "  GROUND_TILES: {18, 15}\n",
      "  AIR_ID: 2\n",
      "  COIN_ID: 20\n",
      "  SOLID_IDS: 21 tiles\n",
      "Loss balance check: ground=0.07, stretch=0.02, sky=0.92\n",
      "ep00 | D=0.817 | G=18.778 | struct=17.074\n",
      "    Structure components: ground=0.350, stretch=0.100, sky=16.623\n",
      "ep01 | D=0.274 | G=15.032 | struct=12.038\n",
      "    Structure components: ground=0.355, stretch=0.100, sky=11.584\n",
      "ep02 | D=0.920 | G=6.431 | struct=5.138\n",
      "    Structure components: ground=0.366, stretch=0.100, sky=4.672\n",
      "ep03 | D=0.737 | G=5.089 | struct=3.632\n",
      "    Structure components: ground=0.367, stretch=0.100, sky=3.165\n",
      "ep04 | D=0.795 | G=4.069 | struct=2.708\n",
      "    Structure components: ground=0.369, stretch=0.100, sky=2.239\n",
      "Loss balance check: ground=0.36, stretch=0.10, sky=0.55\n",
      "ep05 | D=0.874 | G=3.680 | struct=2.421\n",
      "    Structure components: ground=0.371, stretch=0.100, sky=1.950\n",
      "ep06 | D=0.903 | G=3.413 | struct=2.199\n",
      "    Structure components: ground=0.369, stretch=0.100, sky=1.730\n",
      "ep07 | D=0.927 | G=3.163 | struct=2.008\n",
      "    Structure components: ground=0.369, stretch=0.100, sky=1.539\n",
      "ep08 | D=0.940 | G=2.942 | struct=1.806\n",
      "    Structure components: ground=0.368, stretch=0.100, sky=1.338\n",
      "ep09 | D=0.946 | G=2.781 | struct=1.660\n",
      "    Structure components: ground=0.365, stretch=0.100, sky=1.195\n",
      "Loss balance check: ground=0.44, stretch=0.12, sky=0.45\n",
      "ep10 | D=0.957 | G=2.679 | struct=1.556\n",
      "    Structure components: ground=0.365, stretch=0.100, sky=1.092\n",
      "ep11 | D=0.934 | G=2.611 | struct=1.459\n",
      "    Structure components: ground=0.364, stretch=0.100, sky=0.995\n",
      "ep12 | D=0.905 | G=2.583 | struct=1.379\n",
      "    Structure components: ground=0.363, stretch=0.100, sky=0.916\n",
      "ep13 | D=0.876 | G=2.556 | struct=1.327\n",
      "    Structure components: ground=0.365, stretch=0.100, sky=0.863\n",
      "ep14 | D=0.857 | G=2.533 | struct=1.257\n",
      "    Structure components: ground=0.365, stretch=0.100, sky=0.793\n",
      "Loss balance check: ground=0.48, stretch=0.13, sky=0.39\n",
      "ep15 | D=0.847 | G=2.503 | struct=1.196\n",
      "    Structure components: ground=0.364, stretch=0.100, sky=0.732\n",
      "ep16 | D=0.834 | G=2.500 | struct=1.143\n",
      "    Structure components: ground=0.364, stretch=0.100, sky=0.678\n",
      "ep17 | D=0.825 | G=2.450 | struct=1.076\n",
      "    Structure components: ground=0.363, stretch=0.100, sky=0.612\n",
      "ep18 | D=0.824 | G=2.447 | struct=1.030\n",
      "    Structure components: ground=0.365, stretch=0.100, sky=0.565\n",
      "ep19 | D=0.801 | G=2.416 | struct=0.975\n",
      "    Structure components: ground=0.364, stretch=0.100, sky=0.511\n",
      "Loss balance check: ground=0.47, stretch=0.13, sky=0.40\n",
      "ep20 | D=0.812 | G=2.391 | struct=0.920\n",
      "    Structure components: ground=0.365, stretch=0.100, sky=0.455\n",
      "ep21 | D=0.795 | G=2.380 | struct=0.915\n",
      "    Structure components: ground=0.364, stretch=0.100, sky=0.451\n",
      "ep22 | D=0.796 | G=2.430 | struct=0.914\n",
      "    Structure components: ground=0.363, stretch=0.100, sky=0.451\n",
      "ep23 | D=0.811 | G=2.446 | struct=0.905\n",
      "    Structure components: ground=0.364, stretch=0.100, sky=0.441\n",
      "ep24 | D=0.810 | G=2.455 | struct=0.901\n",
      "    Structure components: ground=0.364, stretch=0.100, sky=0.437\n",
      "Loss balance check: ground=0.47, stretch=0.13, sky=0.39\n",
      "ep25 | D=0.779 | G=2.465 | struct=0.906\n",
      "    Structure components: ground=0.364, stretch=0.100, sky=0.442\n",
      "ep26 | D=0.786 | G=2.440 | struct=0.890\n",
      "    Structure components: ground=0.364, stretch=0.100, sky=0.426\n",
      "ep27 | D=0.793 | G=2.480 | struct=0.893\n",
      "    Structure components: ground=0.363, stretch=0.100, sky=0.430\n",
      "ep28 | D=0.794 | G=2.461 | struct=0.888\n",
      "    Structure components: ground=0.363, stretch=0.100, sky=0.425\n",
      "ep29 | D=0.794 | G=2.469 | struct=0.889\n",
      "    Structure components: ground=0.364, stretch=0.100, sky=0.426\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "to_unit = lambda t: t  # Generator output is already in [0, 1]\n",
    "\n",
    "GROUND_TILES = {char_to_int[c] for c in {'X', 'S'} if c in char_to_int}\n",
    "AIR_ID = char_to_int['-']\n",
    "COIN_ID = char_to_int.get('o', AIR_ID)\n",
    "MAX_TILE = max(char_to_int.values())\n",
    "SOLID_IDS = set(range(MAX_TILE + 1)) - {AIR_ID, COIN_ID}\n",
    "\n",
    "def soft_is(u, ids, temp: float = 8.0):\n",
    "    # Smooth mask for selected tile IDs using sigmoids\n",
    "    if not ids:\n",
    "        return torch.zeros_like(u)\n",
    "    masks = []\n",
    "    M = MAX_TILE + 1\n",
    "    for tid in ids:\n",
    "        lo, hi = tid / M, (tid + 1) / M\n",
    "        masks.append(torch.sigmoid((u - lo) * temp) * torch.sigmoid((hi - u) * temp))\n",
    "    return torch.stack(masks).sum(0).clamp(0, 1)\n",
    "\n",
    "def debug_tile_distributions(u):\n",
    "    # Print tile frequencies for debugging\n",
    "    tiles = torch.round(u * MAX_TILE).long()\n",
    "    unique_tiles, counts = torch.unique(tiles, return_counts=True)\n",
    "    total = torch.numel(tiles)\n",
    "    for i, t in enumerate(unique_tiles.cpu().numpy()):\n",
    "        print(f\"Tile {t} ({int_to_char.get(t, '?')}): {counts[i].item()/total*100:.2f}%\")\n",
    "\n",
    "def ground_excess(u, target: float = 0.6):\n",
    "    # Penalize too much or too little ground coverage in bottom two rows\n",
    "    tiles = torch.round(u * MAX_TILE).long()\n",
    "    ground_mask = torch.zeros_like(tiles, dtype=torch.float32)\n",
    "    for tid in GROUND_TILES:\n",
    "        ground_mask += (tiles == tid).float()\n",
    "    ground_mask = ground_mask.clamp(0, 1)\n",
    "    bottom_rows = ground_mask[:, -2:, :]\n",
    "    coverage = bottom_rows.mean((1, 2))\n",
    "    deviation = (coverage - target) ** 2\n",
    "    low_penalty = torch.where(coverage < 0.2, (0.2 - coverage) * 2.0, torch.zeros_like(coverage))\n",
    "    return (deviation + low_penalty).mean() * 0.5\n",
    "\n",
    "def stretch_pen(u, span: int = 6, gap_target: float = 0.3):\n",
    "    # Penalize long solid sections with no gaps in the ground\n",
    "    tiles = torch.round(u * MAX_TILE).long()\n",
    "    ground_mask = torch.zeros_like(tiles, dtype=torch.float32)\n",
    "    for tid in GROUND_TILES:\n",
    "        ground_mask += (tiles == tid).float()\n",
    "    ground_mask = ground_mask.clamp(0, 1)\n",
    "    bottom_rows = ground_mask[:, -2:, :]\n",
    "    bottom_row_avg = bottom_rows.mean(1)\n",
    "    if bottom_row_avg.shape[1] < span:\n",
    "        return torch.tensor(0.0, device=u.device)\n",
    "    windows = bottom_row_avg.unfold(1, span, 1)\n",
    "    ground_ratio = windows.mean(-1)\n",
    "    gap_ratio = 1.0 - ground_ratio\n",
    "    insufficient_gaps = torch.clamp(gap_target - gap_ratio, min=0) ** 2\n",
    "    penalties = insufficient_gaps.sum(1) / windows.shape[1]\n",
    "    noise = torch.rand_like(penalties) * 0.05\n",
    "    return (penalties + noise).mean() * 4.0\n",
    "\n",
    "def sky_solid_pen(u, top_rows: int = 8):\n",
    "    # Penalize solid blocks appearing in the top of the level\n",
    "    tiles = torch.round(u * MAX_TILE).long()\n",
    "    sky_tiles = {AIR_ID, COIN_ID}\n",
    "    sky_mask = torch.ones_like(tiles, dtype=torch.float32)\n",
    "    for tid in sky_tiles:\n",
    "        sky_mask *= (tiles != tid).float()\n",
    "    actual_top = min(top_rows, tiles.shape[1])\n",
    "    top_section = sky_mask[:, :actual_top, :]\n",
    "    row_indices = torch.arange(actual_top, device=u.device)\n",
    "    row_weights = torch.exp(-0.3 * row_indices)\n",
    "    weighted = top_section * row_weights.view(1, -1, 1)\n",
    "    total_possible = row_weights.sum() * tiles.shape[2]\n",
    "    solid_ratio = weighted.sum((1, 2)) / total_possible\n",
    "    noise = torch.rand_like(solid_ratio) * 0.05\n",
    "    return (solid_ratio ** 2 + noise).mean() * 5.0\n",
    "\n",
    "def check_loss_balance(ground_loss, stretch_loss, sky_loss):\n",
    "    # Print loss composition for debugging\n",
    "    total = ground_loss + stretch_loss + sky_loss\n",
    "    if total > 0:\n",
    "        print(f\"Loss balance check: ground={ground_loss/total:.2f}, stretch={stretch_loss/total:.2f}, sky={sky_loss/total:.2f}\")\n",
    "    else:\n",
    "        print(\"Total structure loss is zero!\")\n",
    "\n",
    "bce = nn.BCELoss()\n",
    "optG = torch.optim.Adam(Gnet.parameters(), 1e-4, betas=(0.5, 0.999))\n",
    "optD = torch.optim.Adam(Dnet.parameters(), 1e-4, betas=(0.5, 0.999))\n",
    "λ_struct = 1.0  # Strength of structure loss\n",
    "\n",
    "g_losses, d_losses, struct_losses = [], [], []\n",
    "ground_losses, stretch_losses, sky_losses = [], [], []\n",
    "\n",
    "debug_mode = True\n",
    "sample_interval = 5\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "max_grad_norm = 1.0  # Clip gradients for stability\n",
    "\n",
    "print(\"Starting training with:\")\n",
    "print(f\"  GROUND_TILES: {GROUND_TILES}\")\n",
    "print(f\"  AIR_ID: {AIR_ID}\")\n",
    "print(f\"  COIN_ID: {COIN_ID}\")\n",
    "print(f\"  SOLID_IDS: {len(SOLID_IDS)} tiles\")\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    tot_g, tot_d, tot_struct, n_batches = 0.0, 0.0, 0.0, 0\n",
    "    tot_ground, tot_stretch, tot_sky = 0.0, 0.0, 0.0\n",
    "    debug_this_epoch = debug_mode and (ep % sample_interval == 0)\n",
    "    sky_weight_factor = max(1.0, 3.0 - ep * 0.1)  # Decrease sky penalty over time\n",
    "\n",
    "    for real in loader:\n",
    "        real = real.to(device)\n",
    "        batch_size = real.size(0)\n",
    "\n",
    "        optD.zero_grad()\n",
    "        real_pred = Dnet(real)\n",
    "        d_real_loss = bce(real_pred, torch.ones_like(real_pred))\n",
    "        z = torch.randn(batch_size, LATENT_DIM, device=device)\n",
    "        fake = Gnet(z).detach()\n",
    "        d_fake_loss = bce(Dnet(fake), torch.zeros_like(real_pred))\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(Dnet.parameters(), max_grad_norm)\n",
    "        optD.step()\n",
    "\n",
    "        optG.zero_grad()\n",
    "        z = torch.randn(batch_size, LATENT_DIM, device=device)\n",
    "        gen = Gnet(z)\n",
    "        gen_pred = Dnet(gen)\n",
    "        g_adv_loss = bce(gen_pred, torch.ones_like(gen_pred))\n",
    "\n",
    "        unit = to_unit(gen)\n",
    "        ground_ex = ground_excess(unit, target=0.6)\n",
    "        stretch = stretch_pen(unit, span=6, gap_target=0.3)\n",
    "        sky_pen = sky_solid_pen(unit, top_rows=8)\n",
    "\n",
    "        if debug_this_epoch and n_batches == 0:\n",
    "            check_loss_balance(ground_ex.item(), stretch.item(), sky_pen.item())\n",
    "\n",
    "        ground_weight = 1.0\n",
    "        stretch_weight = 1.0\n",
    "        sky_weight = 1.5 * sky_weight_factor\n",
    "\n",
    "        weighted_ground = ground_weight * ground_ex\n",
    "        weighted_stretch = stretch_weight * stretch\n",
    "        weighted_sky = sky_weight * sky_pen\n",
    "        struct_loss = weighted_ground + weighted_stretch + weighted_sky\n",
    "\n",
    "        g_loss = g_adv_loss + λ_struct * struct_loss\n",
    "        g_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(Gnet.parameters(), max_grad_norm)\n",
    "        optG.step()\n",
    "\n",
    "        tot_g += g_loss.item()\n",
    "        tot_d += d_loss.item()\n",
    "        tot_struct += struct_loss.item()\n",
    "        tot_ground += weighted_ground.item()\n",
    "        tot_stretch += weighted_stretch.item()\n",
    "        tot_sky += weighted_sky.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    g_losses.append(tot_g / n_batches)\n",
    "    d_losses.append(tot_d / n_batches)\n",
    "    struct_losses.append(tot_struct / n_batches)\n",
    "    ground_losses.append(tot_ground / n_batches)\n",
    "    stretch_losses.append(tot_stretch / n_batches)\n",
    "    sky_losses.append(tot_sky / n_batches)\n",
    "\n",
    "    print(f\"ep{ep:02} | D={d_losses[-1]:.3f} | G={g_losses[-1]:.3f} | struct={struct_losses[-1]:.3f}\")\n",
    "    print(f\"    Structure components: ground={ground_losses[-1]:.3f}, stretch={stretch_losses[-1]:.3f}, sky={sky_losses[-1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14cb5307-ff06-4f10-a848-7780b7910fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved level_0229.txt\n",
      "saved level_0230.txt\n",
      "saved level_0231.txt\n"
     ]
    }
   ],
   "source": [
    "import os, re, glob, math, random, torch\n",
    "\n",
    "to_int = lambda t: torch.round(t * MAX_TILE).long()  # Convert normalized tensor to integer tile IDs\n",
    "\n",
    "def _next_name(folder, pat=\"level_*.txt\"):\n",
    "    # Find the next available level filename in the folder\n",
    "    ids = [int(m.group(1)) for p in glob.glob(os.path.join(folder, pat))\n",
    "           if (m := re.search(r\"level_(\\d+)\\.txt$\", os.path.basename(p)))]\n",
    "    return f\"level_{(max(ids)+1) if ids else 0:04}.txt\"\n",
    "\n",
    "def clean_chunk(ch):\n",
    "    # Force bottom two rows to be solid ground\n",
    "    ch[:, -2:, :] = list(GROUND_TILES)[0]\n",
    "    return ch\n",
    "\n",
    "def stitch(parts):\n",
    "    # Combine horizontal patches into full level shape\n",
    "    return torch.cat(parts, dim=2)[:, :LEVEL_HEIGHT, :LEVEL_WIDTH]\n",
    "\n",
    "def carve_random_pits(lvl, cfg: DifficultyConfig):\n",
    "    # Add random pits based on difficulty configuration\n",
    "    if cfg.seed:\n",
    "        random.seed(cfg.seed)\n",
    "    y0, y1 = LEVEL_HEIGHT - 2, LEVEL_HEIGHT - 1\n",
    "    x = 2  # Start with 2 solid tiles on the left\n",
    "    while x < LEVEL_WIDTH - 2:\n",
    "        if random.random() < cfg.pit_freq:\n",
    "            width = max(1, int(random.gauss(cfg.pit_width_mean, 0.7)))\n",
    "            lvl[0, y0:y1 + 1, x:x + width] = AIR_ID\n",
    "            x += width + 2  # Leave space before next pit\n",
    "        else:\n",
    "            x += 1\n",
    "    return lvl\n",
    "\n",
    "SKY_ROWS = 6  # Number of rows at the top considered as sky\n",
    "ALLOWED_IDS_CPU = torch.tensor([AIR_ID, COIN_ID])  # Only air and coins are allowed in sky\n",
    "\n",
    "def _rowwise_probs(H, max_p, min_p, mode=\"exp\", exp_base=4.0, *, device=\"cpu\"):\n",
    "    # Compute deletion probability for each sky row (top to bottom)\n",
    "    t = torch.linspace(0, 1, H, device=device)\n",
    "    if mode == \"linear\":\n",
    "        probs = min_p + (max_p - min_p) * (1 - t)\n",
    "    elif mode == \"quad\":\n",
    "        probs = min_p + (max_p - min_p) * (1 - t) ** 2\n",
    "    elif mode == \"exp\":\n",
    "        probs = min_p + (max_p - min_p) * (exp_base ** (-t))\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'linear', 'quad', or 'exp'\")\n",
    "    return probs\n",
    "\n",
    "def prune_sky(lvl, cfg: DifficultyConfig):\n",
    "    # Remove disallowed tiles from the top sky rows using row-based probabilities\n",
    "    device_lvl = lvl.device\n",
    "    H = min(SKY_ROWS, lvl.shape[1])\n",
    "    probs = _rowwise_probs(H, cfg.sky_max_clear, cfg.sky_min_clear, cfg.sky_curve, device=device_lvl)\n",
    "    allowed_ids = ALLOWED_IDS_CPU.to(device_lvl)\n",
    "\n",
    "    for y in range(H):\n",
    "        p = probs[y].item()\n",
    "        row = lvl[:, y, :]\n",
    "        keep_mask = torch.isin(row, allowed_ids)\n",
    "        delete_mask = (~keep_mask) & (torch.rand_like(row, dtype=torch.float) < p)\n",
    "        row[delete_mask] = AIR_ID\n",
    "    return lvl\n",
    "\n",
    "def ascii_grid(g):\n",
    "    # Convert level tensor into ASCII strings row by row\n",
    "    return [\"\".join(int_to_char[int(t)] for t in g[0, r, :]) for r in range(LEVEL_HEIGHT)]\n",
    "\n",
    "def generate_level(fname=None, preset=\"medium\"):\n",
    "    # Generate one level and save it as a .txt file\n",
    "    cfg = PRESETS[preset] if isinstance(preset, str) else preset\n",
    "    if cfg.seed:\n",
    "        random.seed(cfg.seed)\n",
    "\n",
    "    fname = fname or _next_name(OUTPUT_DIR)\n",
    "    parts = []\n",
    "    chunks = math.ceil(LEVEL_WIDTH / PATCH)\n",
    "    for _ in range(chunks):\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(1, LATENT_DIM, device=device)\n",
    "            patch = Gnet(z).cpu()\n",
    "            parts.append(clean_chunk(to_int(patch).squeeze(0)))\n",
    "\n",
    "    lvl = stitch(parts)\n",
    "    lvl = carve_random_pits(lvl, cfg)\n",
    "    lvl = prune_sky(lvl, cfg)\n",
    "\n",
    "    # Place Mario near the start, 6 tiles above the ground\n",
    "    start_x = 1\n",
    "    start_y = LEVEL_HEIGHT - 8\n",
    "    lvl[0, LEVEL_HEIGHT - 2, 1] = AIR_ID  # Clear default Mario location\n",
    "    lvl[0, start_y, start_x] = START\n",
    "\n",
    "    # Place goal near the end on the ground\n",
    "    lvl[0, LEVEL_HEIGHT - 2, LEVEL_WIDTH - 2] = GOAL\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIR, fname), \"w\") as f:\n",
    "        f.write(\"\\n\".join(ascii_grid(lvl)))\n",
    "    print(\"saved\", fname)\n",
    "\n",
    "for preset in [\"easy\", \"medium\", \"hard\"]:\n",
    "    generate_level(preset=preset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2bd5969-893d-4a1e-85f8-4d6505341290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating visualizations for paper...\n",
      "- Loss curves plotted\n",
      "- Generating sample levels for analysis...\n",
      "- Generated 30 sample levels\n",
      "- Calculated level metrics\n",
      "- Expressive range plotted\n",
      "- Tile distribution plotted\n",
      "- Tile heatmaps plotted\n",
      "All visualizations saved to ./generated_levels/figures\n",
      "\n",
      "Quantitative Results Summary:\n",
      "- Linearity: mean=1.030, std=0.462\n",
      "- Leniency: mean=0.130, std=0.089\n",
      "- Tile Entropy: mean=0.863, std=0.066\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from scipy.stats import entropy\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from collections import Counter\n",
    "\n",
    "# Create directory to save figures\n",
    "FIGURES_DIR = os.path.join(OUTPUT_DIR, \"figures\")\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "\n",
    "def plot_loss_curves():\n",
    "    # Plot GAN and structure loss over training\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(EPOCHS), d_losses, label='Discriminator Loss')\n",
    "    plt.plot(range(EPOCHS), g_losses, label='Generator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('GAN Training Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(EPOCHS), struct_losses, label='Structure Loss', color='green')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Structure Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, 'loss_curves.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def generate_sample_levels(num_samples=30, seed=None):\n",
    "    # Generate sample levels from the generator using all presets\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    levels = []\n",
    "    for i in range(num_samples):\n",
    "        parts = []\n",
    "        chunks = math.ceil(LEVEL_WIDTH / PATCH)\n",
    "        for _ in range(chunks):\n",
    "            with torch.no_grad():\n",
    "                z = torch.randn(1, LATENT_DIM, device=device)\n",
    "                parts.append(clean_chunk(to_int(Gnet(z).cpu()).squeeze(0)))\n",
    "        lvl = stitch(parts)\n",
    "        cfg = PRESETS[[\"easy\", \"medium\", \"hard\"][i % 3]]\n",
    "        lvl = carve_random_pits(lvl, cfg)\n",
    "        lvl = prune_sky(lvl, cfg)\n",
    "        levels.append(lvl)\n",
    "    return levels\n",
    "\n",
    "def calculate_metrics(levels):\n",
    "    # Compute leniency, linearity, entropy for each level\n",
    "    results = []\n",
    "\n",
    "    for lvl in levels:\n",
    "        arr = lvl[0].cpu().numpy()\n",
    "\n",
    "        enemy_count = np.sum(np.isin(arr, list(ENEMIES)))\n",
    "        pit_count = 0\n",
    "        pit_widths = []\n",
    "        in_pit = False\n",
    "        current_width = 0\n",
    "\n",
    "        for x in range(arr.shape[1]):\n",
    "            is_solid = any(arr[y, x] in GROUND_TILES for y in range(LEVEL_HEIGHT - 2, LEVEL_HEIGHT))\n",
    "            if not is_solid:\n",
    "                if not in_pit:\n",
    "                    in_pit = True\n",
    "                    pit_count += 1\n",
    "                current_width += 1\n",
    "            elif in_pit:\n",
    "                pit_widths.append(current_width)\n",
    "                current_width = 0\n",
    "                in_pit = False\n",
    "        if in_pit:\n",
    "            pit_widths.append(current_width)\n",
    "\n",
    "        avg_pit_width = np.mean(pit_widths) if pit_widths else 0\n",
    "        leniency = (enemy_count / (LEVEL_HEIGHT * LEVEL_WIDTH)) + (pit_count * avg_pit_width / LEVEL_WIDTH)\n",
    "\n",
    "        ground_heights = []\n",
    "        for x in range(arr.shape[1]):\n",
    "            for y in range(LEVEL_HEIGHT):\n",
    "                if arr[y, x] in GROUND_TILES:\n",
    "                    ground_heights.append(y)\n",
    "                    break\n",
    "            else:\n",
    "                ground_heights.append(LEVEL_HEIGHT - 1)\n",
    "\n",
    "        linearity = np.std(ground_heights)\n",
    "        tile_counts = Counter(arr.flatten())\n",
    "        probs = np.array(list(tile_counts.values())) / arr.size\n",
    "        tile_entropy = entropy(probs)\n",
    "\n",
    "        results.append({\n",
    "            'leniency': leniency,\n",
    "            'linearity': linearity,\n",
    "            'tile_entropy': tile_entropy,\n",
    "            'pit_count': pit_count,\n",
    "            'avg_pit_width': avg_pit_width\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "def plot_expressive_range(metrics):\n",
    "    # Plot scatter of leniency vs. linearity colored by entropy\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    leniency = [m['leniency'] for m in metrics]\n",
    "    linearity = [m['linearity'] for m in metrics]\n",
    "    tile_entropy = [m['tile_entropy'] for m in metrics]\n",
    "    norm_entropy = [(e - min(tile_entropy)) / (max(tile_entropy) - min(tile_entropy) + 1e-10) for e in tile_entropy]\n",
    "\n",
    "    sc = plt.scatter(linearity, leniency, c=norm_entropy, cmap='viridis',\n",
    "                     alpha=0.7, s=100, edgecolors='w')\n",
    "\n",
    "    plt.colorbar(sc, label='Normalized Tile Entropy')\n",
    "    plt.xlabel('Linearity (terrain variation)')\n",
    "    plt.ylabel('Leniency (lower = easier)')\n",
    "    plt.title('Expressive Range of Generated Levels')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    for i in [0, 10, 20, 29]:\n",
    "        if i < len(metrics):\n",
    "            plt.annotate(f\"Level {i}\", (linearity[i], leniency[i]),\n",
    "                         textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, 'expressive_range.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_tile_distribution(levels):\n",
    "    # Show frequency of each tile type and entropy distribution\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    tile_type_data = {ch: [] for ch in symbols}\n",
    "\n",
    "    for lvl in levels:\n",
    "        arr = lvl[0].cpu().numpy()\n",
    "        total = arr.size\n",
    "        for i, ch in int_to_char.items():\n",
    "            count = np.sum(arr == i)\n",
    "            tile_type_data[ch].append((count / total) * 100)\n",
    "\n",
    "    filtered_data = {ch: data for ch, data in tile_type_data.items() if sum(data) > 0 and ch != '-'}\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    boxplot = plt.boxplot([filtered_data[ch] for ch in filtered_data],\n",
    "                          labels=list(filtered_data.keys()), patch_artist=True)\n",
    "\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(filtered_data)))\n",
    "    for patch, color in zip(boxplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    plt.ylabel('Percentage of Level (%)')\n",
    "    plt.title('Distribution of Tile Types')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    tile_entropies = [m['tile_entropy'] for m in calculate_metrics(levels)]\n",
    "    sns.histplot(tile_entropies, kde=True)\n",
    "    plt.xlabel('Tile Entropy')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Tile Entropy Across Levels')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, 'tile_distribution.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_tile_heatmaps(levels):\n",
    "    # Heatmaps showing where tile types appear on average\n",
    "    combined_heatmap = np.zeros((LEVEL_HEIGHT, LEVEL_WIDTH))\n",
    "    ground_heatmap = np.zeros((LEVEL_HEIGHT, LEVEL_WIDTH))\n",
    "    enemy_heatmap = np.zeros((LEVEL_HEIGHT, LEVEL_WIDTH))\n",
    "\n",
    "    for lvl in levels:\n",
    "        arr = lvl[0].cpu().numpy()\n",
    "        for tid in GROUND_TILES:\n",
    "            ground_heatmap += (arr == tid)\n",
    "        for tid in ENEMIES:\n",
    "            enemy_heatmap += (arr == tid)\n",
    "        combined_heatmap += (arr != AIR_ID)\n",
    "\n",
    "    n = len(levels)\n",
    "    ground_heatmap /= n\n",
    "    enemy_heatmap /= n\n",
    "    combined_heatmap /= n\n",
    "\n",
    "    plt.figure(figsize=(15, 12))\n",
    "\n",
    "    plt.subplot(3, 1, 1)\n",
    "    sns.heatmap(combined_heatmap, cmap=\"YlOrRd\", vmin=0, vmax=1)\n",
    "    plt.title('Heatmap of All Non-Empty Tiles')\n",
    "\n",
    "    plt.subplot(3, 1, 2)\n",
    "    sns.heatmap(ground_heatmap, cmap=\"YlGn\", vmin=0, vmax=1)\n",
    "    plt.title('Heatmap of Ground Tiles')\n",
    "\n",
    "    plt.subplot(3, 1, 3)\n",
    "    if np.max(enemy_heatmap) > 0:\n",
    "        sns.heatmap(enemy_heatmap, cmap=\"Reds\", vmin=0, vmax=0.5)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No enemy tiles detected', ha='center', va='center',\n",
    "                 transform=plt.gca().transAxes, fontsize=14)\n",
    "    plt.title('Heatmap of Enemy Tiles')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, 'tile_heatmaps.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Run all visualizations and print progress\n",
    "print(\"Generating visualizations for paper...\")\n",
    "plot_loss_curves()\n",
    "print(\"- Loss curves plotted\")\n",
    "\n",
    "print(\"- Generating sample levels for analysis...\")\n",
    "sample_levels = generate_sample_levels(num_samples=30, seed=42)\n",
    "print(f\"- Generated {len(sample_levels)} sample levels\")\n",
    "\n",
    "level_metrics = calculate_metrics(sample_levels)\n",
    "print(\"- Calculated level metrics\")\n",
    "\n",
    "plot_expressive_range(level_metrics)\n",
    "print(\"- Expressive range plotted\")\n",
    "\n",
    "plot_tile_distribution(sample_levels)\n",
    "print(\"- Tile distribution plotted\")\n",
    "\n",
    "plot_tile_heatmaps(sample_levels)\n",
    "print(\"- Tile heatmaps plotted\")\n",
    "\n",
    "print(f\"All visualizations saved to {FIGURES_DIR}\")\n",
    "\n",
    "# Print summary stats\n",
    "print(\"\\nQuantitative Results Summary:\")\n",
    "print(f\"- Linearity: mean={np.mean([m['linearity'] for m in level_metrics]):.3f}, std={np.std([m['linearity'] for m in level_metrics]):.3f}\")\n",
    "print(f\"- Leniency: mean={np.mean([m['leniency'] for m in level_metrics]):.3f}, std={np.std([m['leniency'] for m in level_metrics]):.3f}\")\n",
    "print(f\"- Tile Entropy: mean={np.mean([m['tile_entropy'] for m in level_metrics]):.3f}, std={np.std([m['tile_entropy'] for m in level_metrics]):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebfabcff-1b82-4e53-a511-d20cf938eae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating 3 easy levels...\n",
      "  Saved level_easy_0000.txt to ./test_demo\n",
      "  Saved level_easy_0001.txt to ./test_demo\n",
      "  Saved level_easy_0002.txt to ./test_demo\n",
      "\n",
      "Generating 3 medium levels...\n",
      "  Saved level_medium_0000.txt to ./test_demo\n",
      "  Saved level_medium_0001.txt to ./test_demo\n",
      "  Saved level_medium_0002.txt to ./test_demo\n",
      "\n",
      "Generating 3 hard levels...\n",
      "  Saved level_hard_0000.txt to ./test_demo\n",
      "  Saved level_hard_0001.txt to ./test_demo\n",
      "  Saved level_hard_0002.txt to ./test_demo\n",
      "\n",
      "Generation complete! Created 9 levels:\n",
      "  Easy: 3\n",
      "  Medium: 3\n",
      "  Hard: 3\n",
      "All levels saved to: ./test_demo\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "\n",
    "def generate_multiple_levels(output_folder, easy_count=5, medium_count=5, hard_count=5, seed=None):\n",
    "    \"\"\"\n",
    "    Generate multiple levels across easy, medium, and hard presets, saving to disk.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Ensure output folder exists\n",
    "\n",
    "    # Set random seed if provided\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    counts = {\"easy\": 0, \"medium\": 0, \"hard\": 0}  # Count levels by difficulty\n",
    "\n",
    "    # Generate easy levels\n",
    "    print(f\"\\nGenerating {easy_count} easy levels...\")\n",
    "    for i in range(easy_count):\n",
    "        level_seed = random.randint(1, 10000) if seed else 0\n",
    "        fname = f\"level_easy_{i:04d}.txt\"\n",
    "        full_path = os.path.join(output_folder, fname)\n",
    "\n",
    "        # Copy preset and add seed\n",
    "        cfg = PRESETS[\"easy\"]\n",
    "        if level_seed:\n",
    "            cfg = DifficultyConfig(**{**cfg.__dict__, \"seed\": level_seed})\n",
    "\n",
    "        parts = []\n",
    "        for _ in range(math.ceil(LEVEL_WIDTH / PATCH)):\n",
    "            with torch.no_grad():\n",
    "                z = torch.randn(1, LATENT_DIM, device=device)\n",
    "                parts.append(clean_chunk(to_int(Gnet(z).cpu()).squeeze(0)))\n",
    "\n",
    "        lvl = stitch(parts)\n",
    "        lvl = carve_random_pits(lvl, cfg)\n",
    "        lvl = prune_sky(lvl, cfg)\n",
    "\n",
    "        # Place Mario and goal\n",
    "        lvl[0, :, 1] = AIR_ID  # Clear space\n",
    "        lvl[0, LEVEL_HEIGHT - 8, 1] = START\n",
    "        lvl[0, LEVEL_HEIGHT - 2, LEVEL_WIDTH - 2] = GOAL\n",
    "\n",
    "        # Add some coins\n",
    "        if COIN_ID != AIR_ID:\n",
    "            for y in range(4, LEVEL_HEIGHT - 4):\n",
    "                for x in range(4, LEVEL_WIDTH - 4):\n",
    "                    if lvl[0, y, x] == AIR_ID and random.random() < 0.03:\n",
    "                        lvl[0, y, x] = COIN_ID\n",
    "\n",
    "        with open(full_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(ascii_grid(lvl)))\n",
    "\n",
    "        print(f\"  Saved {fname} to {output_folder}\")\n",
    "        counts[\"easy\"] += 1\n",
    "\n",
    "    # Generate medium levels\n",
    "    print(f\"\\nGenerating {medium_count} medium levels...\")\n",
    "    for i in range(medium_count):\n",
    "        level_seed = random.randint(1, 10000) if seed else 0\n",
    "        fname = f\"level_medium_{i:04d}.txt\"\n",
    "        full_path = os.path.join(output_folder, fname)\n",
    "\n",
    "        cfg = PRESETS[\"medium\"]\n",
    "        if level_seed:\n",
    "            cfg = DifficultyConfig(**{**cfg.__dict__, \"seed\": level_seed})\n",
    "\n",
    "        parts = []\n",
    "        for _ in range(math.ceil(LEVEL_WIDTH / PATCH)):\n",
    "            with torch.no_grad():\n",
    "                z = torch.randn(1, LATENT_DIM, device=device)\n",
    "                parts.append(clean_chunk(to_int(Gnet(z).cpu()).squeeze(0)))\n",
    "\n",
    "        lvl = stitch(parts)\n",
    "        lvl = carve_random_pits(lvl, cfg)\n",
    "        lvl = prune_sky(lvl, cfg)\n",
    "\n",
    "        lvl[0, :, 1] = AIR_ID\n",
    "        lvl[0, LEVEL_HEIGHT - 8, 1] = START\n",
    "        lvl[0, LEVEL_HEIGHT - 2, LEVEL_WIDTH - 2] = GOAL\n",
    "\n",
    "        if COIN_ID != AIR_ID:\n",
    "            for y in range(4, LEVEL_HEIGHT - 4):\n",
    "                for x in range(4, LEVEL_WIDTH - 4):\n",
    "                    if lvl[0, y, x] == AIR_ID and random.random() < 0.015:\n",
    "                        lvl[0, y, x] = COIN_ID\n",
    "\n",
    "        with open(full_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(ascii_grid(lvl)))\n",
    "\n",
    "        print(f\"  Saved {fname} to {output_folder}\")\n",
    "        counts[\"medium\"] += 1\n",
    "\n",
    "    # Generate hard levels\n",
    "    print(f\"\\nGenerating {hard_count} hard levels...\")\n",
    "    for i in range(hard_count):\n",
    "        level_seed = random.randint(1, 10000) if seed else 0\n",
    "        fname = f\"level_hard_{i:04d}.txt\"\n",
    "        full_path = os.path.join(output_folder, fname)\n",
    "\n",
    "        cfg = PRESETS[\"hard\"]\n",
    "        if level_seed:\n",
    "            cfg = DifficultyConfig(**{**cfg.__dict__, \"seed\": level_seed})\n",
    "\n",
    "        parts = []\n",
    "        for _ in range(math.ceil(LEVEL_WIDTH / PATCH)):\n",
    "            with torch.no_grad():\n",
    "                z = torch.randn(1, LATENT_DIM, device=device)\n",
    "                parts.append(clean_chunk(to_int(Gnet(z).cpu()).squeeze(0)))\n",
    "\n",
    "        lvl = stitch(parts)\n",
    "        lvl = carve_random_pits(lvl, cfg)\n",
    "        lvl = prune_sky(lvl, cfg)\n",
    "\n",
    "        lvl[0, :, 1] = AIR_ID\n",
    "        lvl[0, LEVEL_HEIGHT - 8, 1] = START\n",
    "        lvl[0, LEVEL_HEIGHT - 2, LEVEL_WIDTH - 2] = GOAL\n",
    "\n",
    "        if COIN_ID != AIR_ID:\n",
    "            for y in range(4, LEVEL_HEIGHT - 4):\n",
    "                for x in range(4, LEVEL_WIDTH - 4):\n",
    "                    if lvl[0, y, x] == AIR_ID and random.random() < 0.005:\n",
    "                        lvl[0, y, x] = COIN_ID\n",
    "\n",
    "        with open(full_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(ascii_grid(lvl)))\n",
    "\n",
    "        print(f\"  Saved {fname} to {output_folder}\")\n",
    "        counts[\"hard\"] += 1\n",
    "\n",
    "    # Print summary\n",
    "    total = sum(counts.values())\n",
    "    print(f\"\\nGeneration complete! Created {total} levels:\")\n",
    "    for k in [\"easy\", \"medium\", \"hard\"]:\n",
    "        print(f\"  {k.capitalize()}: {counts[k]}\")\n",
    "    print(f\"All levels saved to: {output_folder}\")\n",
    "\n",
    "# Set output directory and call the generator\n",
    "MY_OUTPUT_FOLDER = \"./test_demo\"\n",
    "\n",
    "generate_multiple_levels(\n",
    "    output_folder=MY_OUTPUT_FOLDER,\n",
    "    easy_count=3,\n",
    "    medium_count=3,\n",
    "    hard_count=3,\n",
    "    seed=None  # Use fixed value for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb092036-ca31-4b59-b3d4-4bc043cb046b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
